{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a8f8f07"
      },
      "source": [
        "## Load and Inspect Data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "bba0eda4",
        "outputId": "9a8d3e98-1a22-43df-fb4f-a0232af6dfa2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the historical cryptocurrency data\n",
        "df = pd.read_csv('historical_cryptocurrency_data.csv')\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print('First 5 rows of the DataFrame:')\n",
        "print(df.head())\n",
        "\n",
        "# Print the concise summary of the DataFrame\n",
        "print('\\nDataFrame Info:')\n",
        "df.info()\n",
        "\n",
        "# Check for and display the sum of missing values for each column\n",
        "print('\\nMissing values per column:')\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'historical_cryptocurrency_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3241191306.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the historical cryptocurrency data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'historical_cryptocurrency_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display the first 5 rows of the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'historical_cryptocurrency_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous code failed because the `historical_cryptocurrency_data.csv` file was not found. To fix this, I will first create a dummy CSV file with the expected name and some sample cryptocurrency data, and then proceed with the original steps of loading and inspecting the data."
      ],
      "metadata": {
        "id": "uP7ZofnzJmAf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oG3w9Y7AJ6Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55fc7b1e",
        "outputId": "8bbbdeaa-cb0d-449f-ec97-e3617a1bb7fc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a dummy historical cryptocurrency data CSV file for demonstration\n",
        "# In a real scenario, this file would be provided or downloaded.\n",
        "dates = pd.date_range(start='2022-01-01', periods=100)\n",
        "np.random.seed(42)\n",
        "df_dummy = pd.DataFrame({\n",
        "    'Date': dates,\n",
        "    'Open': np.random.uniform(30000, 50000, 100),\n",
        "    'High': np.random.uniform(50000, 55000, 100),\n",
        "    'Low': np.random.uniform(25000, 30000, 100),\n",
        "    'Close': np.random.uniform(28000, 52000, 100),\n",
        "    'Volume': np.random.uniform(1e9, 5e9, 100),\n",
        "    'Market Cap': np.random.uniform(5e11, 1e12, 100)\n",
        "})\n",
        "df_dummy.to_csv('historical_cryptocurrency_data.csv', index=False)\n",
        "\n",
        "# Load the historical cryptocurrency data\n",
        "df = pd.read_csv('historical_cryptocurrency_data.csv')\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print('First 5 rows of the DataFrame:')\n",
        "print(df.head())\n",
        "\n",
        "# Print the concise summary of the DataFrame\n",
        "print('DataFrame Info:')\n",
        "df.info()\n",
        "\n",
        "# Check for and display the sum of missing values for each column\n",
        "print('Missing values per column:')\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "         Date          Open          High           Low         Close  \\\n",
            "0  2022-01-01  37490.802377  50157.145928  28210.158231  29240.361308   \n",
            "1  2022-01-02  49014.286128  53182.052056  25420.699825  40752.511158   \n",
            "2  2022-01-03  44639.878836  51571.779905  25808.143570  40975.242919   \n",
            "3  2022-01-04  41973.169684  52542.853456  29492.770943  43298.317636   \n",
            "4  2022-01-05  33120.372809  54537.832370  28032.145298  45426.192009   \n",
            "\n",
            "         Volume    Market Cap  \n",
            "0  1.412495e+09  8.490809e+11  \n",
            "1  4.610212e+09  7.680482e+11  \n",
            "2  3.021009e+09  6.547638e+11  \n",
            "3  4.305830e+09  9.068975e+11  \n",
            "4  2.280198e+09  8.423656e+11  \n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Date        100 non-null    object \n",
            " 1   Open        100 non-null    float64\n",
            " 2   High        100 non-null    float64\n",
            " 3   Low         100 non-null    float64\n",
            " 4   Close       100 non-null    float64\n",
            " 5   Volume      100 non-null    float64\n",
            " 6   Market Cap  100 non-null    float64\n",
            "dtypes: float64(6), object(1)\n",
            "memory usage: 5.6+ KB\n",
            "Missing values per column:\n",
            "Date          0\n",
            "Open          0\n",
            "High          0\n",
            "Low           0\n",
            "Close         0\n",
            "Volume        0\n",
            "Market Cap    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous code block failed due to a `SyntaxError: unterminated string literal` because the `print` statements for 'DataFrame Info:' and 'Missing values per column:' were incorrectly split across multiple lines. I will correct these print statements by ensuring the string literals are properly formatted with newline characters.\n"
      ],
      "metadata": {
        "id": "vRr2VuuSJ-16"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LTUApXgnJ-md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d66b682d",
        "outputId": "0fa04cf6-7284-4639-cc48-c417b3f7e216"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a dummy historical cryptocurrency data CSV file for demonstration\n",
        "# In a real scenario, this file would be provided or downloaded.\n",
        "dates = pd.date_range(start='2022-01-01', periods=100)\n",
        "np.random.seed(42)\n",
        "df_dummy = pd.DataFrame({\n",
        "    'Date': dates,\n",
        "    'Open': np.random.uniform(30000, 50000, 100),\n",
        "    'High': np.random.uniform(50000, 55000, 100),\n",
        "    'Low': np.random.uniform(25000, 30000, 100),\n",
        "    'Close': np.random.uniform(28000, 52000, 100),\n",
        "    'Volume': np.random.uniform(1e9, 5e9, 100),\n",
        "    'Market Cap': np.random.uniform(5e11, 1e12, 100)\n",
        "})\n",
        "df_dummy.to_csv('historical_cryptocurrency_data.csv', index=False)\n",
        "\n",
        "# Load the historical cryptocurrency data\n",
        "df = pd.read_csv('historical_cryptocurrency_data.csv')\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print('First 5 rows of the DataFrame:')\n",
        "print(df.head())\n",
        "\n",
        "# Print the concise summary of the DataFrame\n",
        "print('\\nDataFrame Info:')\n",
        "df.info()\n",
        "\n",
        "# Check for and display the sum of missing values for each column\n",
        "print('\\nMissing values per column:')\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "         Date          Open          High           Low         Close  \\\n",
            "0  2022-01-01  37490.802377  50157.145928  28210.158231  29240.361308   \n",
            "1  2022-01-02  49014.286128  53182.052056  25420.699825  40752.511158   \n",
            "2  2022-01-03  44639.878836  51571.779905  25808.143570  40975.242919   \n",
            "3  2022-01-04  41973.169684  52542.853456  29492.770943  43298.317636   \n",
            "4  2022-01-05  33120.372809  54537.832370  28032.145298  45426.192009   \n",
            "\n",
            "         Volume    Market Cap  \n",
            "0  1.412495e+09  8.490809e+11  \n",
            "1  4.610212e+09  7.680482e+11  \n",
            "2  3.021009e+09  6.547638e+11  \n",
            "3  4.305830e+09  9.068975e+11  \n",
            "4  2.280198e+09  8.423656e+11  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Date        100 non-null    object \n",
            " 1   Open        100 non-null    float64\n",
            " 2   High        100 non-null    float64\n",
            " 3   Low         100 non-null    float64\n",
            " 4   Close       100 non-null    float64\n",
            " 5   Volume      100 non-null    float64\n",
            " 6   Market Cap  100 non-null    float64\n",
            "dtypes: float64(6), object(1)\n",
            "memory usage: 5.6+ KB\n",
            "\n",
            "Missing values per column:\n",
            "Date          0\n",
            "Open          0\n",
            "High          0\n",
            "Low           0\n",
            "Close         0\n",
            "Volume        0\n",
            "Market Cap    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f54bf495"
      },
      "source": [
        "## Data Cleaning and Preprocessing\n",
        "\n",
        "\n",
        "Clean the dataset by handling missing values (e.g., imputation or removal), addressing outliers, and converting data types as necessary to prepare it for feature engineering and model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95bd6693"
      },
      "source": [
        "\n",
        "First, I'll convert the 'Date' column to datetime objects to enable time-series analysis. Then, I'll reconfirm that there are no missing values in the dataset after this conversion. Finally, I'll consider displaying descriptive statistics and a markdown block to guide on how to identify and handle outliers, as the prompt asks to 'consider' potential outliers and decide on a strategy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c42be487",
        "outputId": "ad7904ee-03d8-4b4a-80e5-03ca40fe5f84"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the 'Date' column to datetime objects\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Recheck for missing values after conversion\n",
        "print('Missing values after Date column conversion:')\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Display descriptive statistics for numerical columns to aid in outlier consideration\n",
        "print('\\nDescriptive statistics for numerical columns:')\n",
        "print(df.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after Date column conversion:\n",
            "Date          0\n",
            "Open          0\n",
            "High          0\n",
            "Low           0\n",
            "Close         0\n",
            "Volume        0\n",
            "Market Cap    0\n",
            "dtype: int64\n",
            "\n",
            "Descriptive statistics for numerical columns:\n",
            "                      Date          Open          High           Low  \\\n",
            "count                  100    100.000000    100.000000    100.000000   \n",
            "mean   2022-02-19 12:00:00  39403.614868  52489.158616  27588.006654   \n",
            "min    2022-01-01 00:00:00  30110.442342  50034.760653  25025.307919   \n",
            "25%    2022-01-25 18:00:00  33864.015214  51210.022632  26384.399319   \n",
            "50%    2022-02-19 12:00:00  39282.849094  52528.124286  27812.774664   \n",
            "75%    2022-03-16 06:00:00  44604.062384  53830.917990  28761.834711   \n",
            "max    2022-04-10 00:00:00  49737.738732  54928.252271  29950.269251   \n",
            "std                    NaN   5949.788220   1465.556263   1467.131235   \n",
            "\n",
            "              Close        Volume    Market Cap  \n",
            "count    100.000000  1.000000e+02  1.000000e+02  \n",
            "mean   39787.574579  3.064183e+09  7.626499e+11  \n",
            "min    28345.443727  1.043351e+09  5.072723e+11  \n",
            "25%    33990.758104  2.055739e+09  6.277602e+11  \n",
            "50%    40233.239283  3.101598e+09  7.641010e+11  \n",
            "75%    45658.660289  4.187537e+09  9.055701e+11  \n",
            "max    51772.123408  4.971859e+09  9.998588e+11  \n",
            "std     7042.853247  1.274404e+09  1.485610e+11  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f684101"
      },
      "source": [
        "#### Outlier Consideration and Strategy\n",
        "\n",
        "Based on the descriptive statistics, we can observe the `min`, `max`, `mean`, and `std` deviations for each numerical column. While the current dummy data is synthetically generated and may not exhibit extreme outliers, in a real-world scenario, you would proceed as follows:\n",
        "\n",
        "1.  **Visualize Outliers**: Create visualizations like box plots (`df.boxplot()`) or histograms for each numerical column ('Open', 'High', 'Low', 'Close', 'Volume', 'Market Cap'). These plots help visually identify values that fall significantly outside the typical range.\n",
        "    *   For example, you could use: `import matplotlib.pyplot as plt` and then `plt.figure(figsize=(15, 5)); df[['Open', 'High', 'Low', 'Close']].boxplot(); plt.title('Box Plot for Price-related Columns'); plt.show()`\n",
        "\n",
        "2.  **Quantify Outliers**: Use statistical methods like the Interquartile Range (IQR) rule. Any data point falling below `Q1 - 1.5 * IQR` or above `Q3 + 1.5 * IQR` is typically considered an outlier.\n",
        "\n",
        "3.  **Decide on a Strategy**: Once potential outliers are identified, choose an appropriate handling strategy based on the context and impact on your analysis/model:\n",
        "    *   **Removal**: If outliers are clearly data entry errors or extremely rare events that skew the data, and their removal doesn't significantly reduce the dataset size, they can be removed.\n",
        "    *   **Capping/Winsorization**: Replace outlier values with a specific percentile (e.g., values above the 99th percentile are set to the 99th percentile value, and values below the 1st percentile are set to the 1st percentile value). This reduces the impact of extreme values without removing them.\n",
        "    *   **Transformation**: Apply mathematical transformations (e.g., log transformation) to reduce the skewness caused by outliers.\n",
        "    *   **Imputation**: Treat outliers as missing values and impute them using appropriate methods (e.g., mean, median, or more sophisticated techniques).\n",
        "    *   **Keep as is**: Sometimes, outliers represent important information (e.g., a flash crash or a sudden price surge) and should be kept, especially in financial time series analysis. In such cases, robust models that are less sensitive to outliers might be preferred.\n",
        "\n",
        "For this specific dummy dataset, the descriptive statistics do not indicate any obvious extreme outliers that require immediate intervention, as `min` and `max` values are within a reasonable range given the `mean` and `std`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a665fa4"
      },
      "source": [
        "## Feature Engineering - Volatility Calculation\n",
        "\n",
        "\n",
        "Engineer features relevant for volatility prediction. This will include calculating historical volatility (e.g., using rolling standard deviation of returns) as the target variable. Additionally, create other relevant features from OHLC prices, trading volume, and market capitalization, such as daily returns, price ranges, and lagged features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "951a9387"
      },
      "source": [
        "\n",
        "I will calculate daily returns, historical volatility (annualized rolling standard deviation of daily returns), price ranges, and lagged features for 'Close' and 'Volume', then handle any resulting missing values by dropping those rows.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb406e7c",
        "outputId": "f6f2d3ef-be66-45f2-aa70-237858c7ab18"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Calculate Daily Returns\n",
        "df['Daily_Return'] = df['Close'].pct_change()\n",
        "\n",
        "# 2. Calculate Historical Volatility (annualized rolling standard deviation of daily returns)\n",
        "# Use a 7-day rolling window, then annualize by multiplying by sqrt(365)\n",
        "df['Volatility'] = df['Daily_Return'].rolling(window=7).std() * np.sqrt(365)\n",
        "\n",
        "# 3. Create Price Range Features\n",
        "df['Price_Range_HL'] = df['High'] - df['Low']\n",
        "df['Price_Range_OC'] = df['Open'] - df['Close']\n",
        "\n",
        "# 4. Create Lagged Features\n",
        "df['Close_Lag_1'] = df['Close'].shift(1)\n",
        "df['Volume_Lag_1'] = df['Volume'].shift(1)\n",
        "\n",
        "# 5. Handle missing values created by rolling window or lagging operations by dropping rows\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Display the first few rows with new features and check info to confirm non-nulls\n",
        "print(\"DataFrame with new features:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Info after feature engineering and dropping NaNs:\")\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame with new features:\n",
            "         Date          Open          High           Low         Close  \\\n",
            "7  2022-01-08  47323.522915  53777.755693  28317.508846  35750.955351   \n",
            "8  2022-01-09  42022.300235  51143.990827  25025.307919  47084.468674   \n",
            "9  2022-01-10  44161.451556  50384.899549  25804.040257  34499.974030   \n",
            "10 2022-01-11  30411.689886  51448.757265  27743.668947  38535.314097   \n",
            "11 2022-01-12  49398.197043  50806.106436  28459.475988  29882.953152   \n",
            "\n",
            "          Volume    Market Cap  Daily_Return  Volatility  Price_Range_HL  \\\n",
            "7   1.043351e+09  9.112686e+11     -0.114883    3.689500    25460.246847   \n",
            "8   4.621528e+09  9.749000e+11      0.317013    3.264260    26118.682908   \n",
            "9   1.365147e+09  8.628598e+11     -0.267275    3.930314    24580.859292   \n",
            "10  2.277255e+09  8.067076e+11      0.116966    4.012028    23705.088318   \n",
            "11  4.800248e+09  7.091215e+11     -0.224531    4.295703    22346.630448   \n",
            "\n",
            "    Price_Range_OC   Close_Lag_1  Volume_Lag_1  \n",
            "7     11572.567565  40391.208359  2.556807e+09  \n",
            "8     -5062.168440  35750.955351  1.043351e+09  \n",
            "9      9661.477526  47084.468674  4.621528e+09  \n",
            "10    -8123.624211  34499.974030  1.365147e+09  \n",
            "11    19515.243891  38535.314097  2.277255e+09  \n",
            "\n",
            "DataFrame Info after feature engineering and dropping NaNs:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 93 entries, 7 to 99\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   Date            93 non-null     datetime64[ns]\n",
            " 1   Open            93 non-null     float64       \n",
            " 2   High            93 non-null     float64       \n",
            " 3   Low             93 non-null     float64       \n",
            " 4   Close           93 non-null     float64       \n",
            " 5   Volume          93 non-null     float64       \n",
            " 6   Market Cap      93 non-null     float64       \n",
            " 7   Daily_Return    93 non-null     float64       \n",
            " 8   Volatility      93 non-null     float64       \n",
            " 9   Price_Range_HL  93 non-null     float64       \n",
            " 10  Price_Range_OC  93 non-null     float64       \n",
            " 11  Close_Lag_1     93 non-null     float64       \n",
            " 12  Volume_Lag_1    93 non-null     float64       \n",
            "dtypes: datetime64[ns](1), float64(12)\n",
            "memory usage: 10.2 KB\n"
          ]
        }
      ]
    }
  ]
}